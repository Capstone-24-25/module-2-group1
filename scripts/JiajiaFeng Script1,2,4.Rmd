
## Preparation
```{r}
load('data2/claims-raw.RData')
```

```{r}
ls()
```

```{r}
library(rvest)
library(tidytext)
library(dplyr)
library(tidyverse)
library(textstem)
library(rvest)
library(qdapRegex)
library(stopwords)
library(tokenizers)
```


## Preliminary Task1 (5 steps)

### 1.Scrape both header and paragraph content
```{r}

# Why use tryCatch: prevent the entire script from failing due to an issue with a single piece of HTML content
extract_content <- function(html_content) {
  tryCatch({
    # Read the HTML content
    page <- read_html(html_content)
    
    # Extract headers and paragraphs
    headers <- page %>% html_nodes("h1, h2, h3") %>% html_text()
    paragraphs <- page %>% html_nodes("p") %>% html_text()
    
    # Combine headers and paragraphs
    combined_content <- c(headers, paragraphs)
    return(paste(combined_content, collapse = " "))
  }, error = function(e) {
    # Return NA or an empty string if an error occurs
    return(NA)
  })
}

# Apply the function to the 'text_tmp' column
claims_raw$content_combined <- sapply(claims_raw$text_tmp, extract_content)

```

### 2.Tokenize the text
```{r}
# Tokenize the text data
data("stop_words")

tokenized_data <- claims_raw %>%
  unnest_tokens(word, content_combined) %>%
  anti_join(stop_words, by = "word")  # Remove stop words

# Create a document-term matrix (DTM)
dtm <- tokenized_data %>%
  count(.id, word) %>%
  cast_dtm(document = .id, term = word, value = n)

dtm_matrix <- as.matrix(dtm)

```

### 3.Principal Component Analysis (PCA)
```{r}
threshold <- 5 # reduce running time
dtm_filtered <- dtm_matrix[, colSums(dtm_matrix) > threshold]
pca_result <- prcomp(dtm_filtered, center = TRUE, scale. = TRUE)

```

### 4.Logistic Principal Component Regression
```{r}
# fix error: differing number of rows: pca_scores:2120, claims_raw$bclass:2165
rows_to_keep <- rownames(dtm_matrix)
claims_raw_filtered <- claims_raw %>% filter(.id %in% rows_to_keep)
```

```{r}
# Extract PCA scores and combine with the adjusted 'bclass', which is 'binary_class'
pca_scores <- pca_result$x

data_for_model <- data.frame(pca_scores, binary_class = claims_raw_filtered$bclass)
data_for_model$binary_class <- as.factor(data_for_model$binary_class)
```



```{r}
# Fix Warning: glm.fit: algorithm did not converge
binary_class_index <- which(names(data_for_model) == "binary_class")

# Choose the first 500 components (through Cumulative Variance Explained) and binary class column
data_for_model_reduced <- data_for_model[, c(1:500, binary_class_index)] 


names(data_for_model_reduced)
```


```{r}
# Fit logistic regression model using PCA components
logistic_model <- glm(binary_class ~ ., data = data_for_model_reduced, family = binomial)
```
### 5. Are binary class predictions improved using logistic principal component regression?
```{r}
library(pROC)

predicted_probs <- predict(logistic_model, type = "response")

# AUC after PCA
roc_curve <- roc(data_for_model_reduced$binary_class, predicted_probs)
auc(roc_curve)

# ROC Curve
plot(roc_curve)

```
Yes, the binary class predictions are significantly improved using logistic principal component regression compared to random guessing has an AUC of 0.5. After including 500 principal components, the AUC increased to 0.8268, which demonstrates a strong ability to distinguish between the two classes. 




## Preliminary Task 2 ()

### 1.Secondary Tokenization to obtain bigrams
```{r}
names(claims_raw) 
```
```{r}
# Tokenize the text to obtain bigrams
bigram_data <- claims_raw %>%
  unnest_tokens(bigram, content_combined, token = "ngrams", n = 2)


```

### 2.Fit Logistic Regression on word-tokenized data (unigrams) as baseline
```{r}
# What we do in task1  

# Fit logistic regression on PCA of word-tokenized data
pca_scores_words <- pca_result$x
word_model <- glm(binary_class ~ ., data = data_for_model_reduced, family = binomial)

# Predicted log-odds-ratios
word_predicted_log_odds <- predict(word_model, type = "link")


```
### 3.Input Predicted Log-Odds and PCA Scores of Bigrams
```{r}
# Fix error: memory limit 
# Count bigram frequencies across all documents
bigram_counts <- bigram_data %>%
  count(bigram) %>%
  filter(n > 5)  # Keep bigrams that occur more than 5 times

# Filter the bigram_data to include only frequent bigrams
bigram_data_filtered <- bigram_data %>%
  filter(bigram %in% bigram_counts$bigram)

# Create a smaller DTM
bigram_dtm <- bigram_data_filtered %>%
  count(.id, bigram) %>%
  cast_dtm(document = .id, term = bigram, value = n)

bigram_matrix <- as.matrix(bigram_dtm)

```

```{r}
bigram_pca_result <- prcomp(bigram_matrix, center = TRUE, scale. = TRUE)

```

```{r}
# Extract the top 10 principal components from bigram PCA
bigram_pca_scores <- bigram_pca_result$x
combined_data <- data.frame(
  log_odds = word_predicted_log_odds,
  bigram_pca_scores = bigram_pca_scores[, 1:10],  # Use top 10 bigram components
  binary_class = claims_raw_filtered$bclass
)
```


## Preliminary Task 2 Ver.2 ()
### 1.Bigram Tokenization
```{r}
# Bigram Tokenization
library(tidytext)

bigram_tokens <- claims_raw %>%
  unnest_tokens(output = bigram, input = content_combined, token = "ngrams", n = 2)

```
### 2.Filter Low-frequency Bigram
```{r}
# Filter frequent bigrams
bigram_counts <- bigram_tokens %>%
  count(bigram) %>%
  filter(n > 5)  # Only keep bigrams appearing more than 5 times

filtered_bigram_tokens <- bigram_tokens %>%
  filter(bigram %in% bigram_counts$bigram)
```

### 3.Construct the DTM of Bigram
```{r}
# Create a Document-Term Matrix for bigrams
bigram_dtm <- filtered_bigram_tokens %>%
  count(.id, bigram) %>%
  cast_dtm(document = .id, term = bigram, value = n)

```
### 4.PCA on Bigram's DTM
```{r}
# Convert to a dense matrix and perform PCA
bigram_matrix <- as.matrix(bigram_dtm)

# Perform PCA on the filtered bigram DTM
bigram_pca <- prcomp(bigram_matrix, center = TRUE, scale. = TRUE)

# Extract top N components (adjustable)
bigram_pca_scores <- bigram_pca$x[, 1:10]  # Use top 10 components

```

### 5. Combine Log-Odds of Word Prediction(unigram) and PCA Scores of Bigram

```{r}
# What we do in task1  

# Fit logistic regression on PCA of word-tokenized data
pca_scores_words <- pca_result$x
#word_model <- glm(binary_class ~ ., data = data_for_model_reduced, family = binomial)

# Predicted log-odds-ratios
predicted_log_odds <- predict(logistic_model, type = "link")

```

```{r}
# Step 1: Identify rows to keep
rows_to_keep <- intersect(
  names(predicted_log_odds),  # Use names() for vectors
  rownames(bigram_pca_scores)
)

# Step 2: Filter claims_raw_filtered to keep only matching rows
claims_raw_filtered <- claims_raw_filtered %>%
  filter(.id %in% rows_to_keep)

# Step 3: Subset predicted_log_odds and bigram_pca_scores to the same rows
predicted_log_odds <- predicted_log_odds[rows_to_keep]  # Simple indexing for vectors
bigram_pca_scores <- bigram_pca_scores[rows_to_keep, , drop = FALSE]  # Subset matrix

# Step 4: Combine aligned datasets
combined_features <- data.frame(
  log_odds_unigram = predicted_log_odds,
  bigram_pca_scores,
  binary_class = claims_raw_filtered$bclass  # Ensure alignment
)

```


```{r}
# Combine unigram log-odds and bigram PCA scores
combined_features <- data.frame(
  log_odds_unigram = predicted_log_odds,  # From your unigram model
  bigram_pca_scores,  # Top 10 bigram PCA scores
  binary_class = claims_raw_filtered$bclass  # Ensure consistent alignment
)

```



## Primary Task 1 ()

### 1. Load and Preprocess the Data
#### 1.1 Content Extraction
```{r}
load("data2/claims-raw.RData")
load("data2/claims-test.RData")

```

```{r}
nrow(claims_raw)
nrow(claims_test)
```
#### 1.2 Tokenization and Cleaning
```{r}

# Why use tryCatch: prevent the entire script from failing due to an issue with a single piece of HTML content
extract_content <- function(html_content) {
  tryCatch({
    # Read the HTML content
    page <- read_html(html_content)
    
    # Extract headers and paragraphs
    headers <- page %>% html_nodes("h1, h2, h3") %>% html_text()
    paragraphs <- page %>% html_nodes("p") %>% html_text()
    
    # Combine headers and paragraphs
    combined_content <- c(headers, paragraphs)
    return(paste(combined_content, collapse = " "))
  }, error = function(e) {
    # Return NA or an empty string if an error occurs
    return(NA)
  })
}

# Apply the function to the 'text_tmp' column
claims_raw$content_combined <- sapply(claims_raw$text_tmp, extract_content)
claims-test$content_combined <- sapply(claims-test$text_tmp, extract_content)

```

```{r}
library(tidytext)

# Tokenize and clean training data
train_tokens <- claims_raw %>%
  unnest_tokens(word, content_combined) %>%
  anti_join(stop_words, by = "word") %>%
  count(.id, word)

# Tokenize and clean test data
test_tokens <- claims_test %>%
  unnest_tokens(word, content_combined) %>%
  anti_join(stop_words, by = "word") %>%
  count(.id, word)
```


#### 1.3 Create Document-Term Matrices (DTMs)
```{r}
train_dtm <- train_tokens %>%
  cast_dtm(document = .id, term = word, value = n)

test_dtm <- test_tokens %>%
  cast_dtm(document = .id, term = word, value = n)

ncol(train_dtm)
ncol(test_dtm)

```

### 2.Train Models
#### 2.1 Binary Classification with Logistic Regression
```{r}
# Ensure Task 1 logistic model is available (don't forget to run it in the task1)
binary_model <- logistic_model  # Task 1 logistic regression model

saveRDS(binary_model, "binary_model.rds")

```

#### 2.2 Multiclass Classification with SVM

```{r}
library(e1071)

# Convert training DTM to matrix
train_matrix <- as.matrix(train_dtm)

# Multiclass labels
train_labels <- claims_raw$mclass  # Ensure this column exists in your data

```

```{r}
#Fix error train_matrix: 2120 and train_labels: 2165 
cat("Rows in train_matrix:", nrow(train_matrix), "\n")
cat("Rows in train_labels:", length(train_labels), "\n")

rows_to_keep <- rownames(train_matrix)

claims_raw_aligned <- claims_raw %>%
  filter(.id %in% rows_to_keep)

aligned_labels <- claims_raw_aligned$mclass

# Verify alignment
cat("Rows in aligned_labels:", length(aligned_labels), "\n")
cat("Rows in train_matrix (should match):", nrow(train_matrix), "\n")

```

```{r}

# Train SVM model
svm_multiclass_model <- svm(
  x = train_matrix,
  y = as.factor(aligned_labels),
  type = "C-classification", 
  kernel = "linear"           
)

# Save the SVM model
saveRDS(svm_multiclass_model, "svm_multiclass_model.rds")

```
#### Plan B modelï¼š
```{r}
library(randomForest)

# Train Random Forest model
rf_multiclass_model <- randomForest(
  x = train_matrix, 
  y = as.factor(aligned_labels), 
  ntree = 100,            # Number of trees
  mtry = sqrt(ncol(train_matrix))  # Number of features considered at each split
)

# Save the model
saveRDS(rf_multiclass_model, "rf_multiclass_model.rds")

```

### 3: Make Predictions
#### 3.0 Fix Errors before make Test Matrix

```{r}
#Fix error: train dtm and test dtm have different number of columns
anyNA(colnames(train_dtm))  # Check for NA column names
colnames(train_dtm)[is.na(colnames(train_dtm))] <- "UNKNOWN"
anyNA(colnames(test_dtm))  # Check for NA column names
colnames(test_dtm)[is.na(colnames(test_dtm))] <- "UNKNOWN"
# Check for missing columns in test_dtm
missing_cols <- setdiff(colnames(train_dtm), colnames(test_dtm))
print(missing_cols)  # Print missing column names

```

```{r}
# Add missing columns to test_dtm
missing_cols <- setdiff(colnames(train_dtm), colnames(test_dtm))
test_dtm_aligned <- cbind(test_dtm, matrix(0, nrow = nrow(test_dtm), ncol = length(missing_cols)))
colnames(test_dtm_aligned) <- c(colnames(test_dtm), missing_cols)

# Reorder columns to match train_dtm
test_dtm_aligned <- test_dtm_aligned[, colnames(train_dtm), drop = FALSE]

```
```{r}
# Verify dimensions match
cat("Columns in train_dtm:", ncol(train_dtm), "\n")
cat("Columns in test_dtm_aligned:", ncol(test_dtm_aligned), "\n")

# Check column name consistency
all.equal(colnames(train_dtm), colnames(test_dtm_aligned))

```

#### 3.1 Prepare Aligned Test Matrix

```{r}
test_matrix <- as.matrix(test_dtm_aligned)
head(test_dtm_aligned)
```

#### 3.2 Binary prediction
```{r}
# Check column names
train_cols <- colnames(train_matrix)
test_cols <- colnames(test_matrix_aligned)

# Identify missing columns in test_matrix_aligned
missing_cols <- setdiff(train_cols, test_cols)
cat("Number of missing columns in test_matrix_aligned:", length(missing_cols), "\n")

# Identify extra columns in test_matrix_aligned
extra_cols <- setdiff(test_cols, train_cols)
cat("Number of extra columns in test_matrix_aligned:", length(extra_cols), "\n")

# Check for NA or invalid column names
anyNA(train_cols)
anyNA(test_cols)

# Add missing columns with zeros
if (length(missing_cols) > 0) {
  test_matrix_aligned <- cbind(
    test_matrix_aligned, 
    matrix(0, nrow = nrow(test_matrix_aligned), ncol = length(missing_cols))
  )
  colnames(test_matrix_aligned)[(ncol(test_matrix_aligned) - length(missing_cols) + 1):ncol(test_matrix_aligned)] <- missing_cols
}

duplicated(train_cols)

colnames(train_matrix)[is.na(colnames(train_matrix))] <- "UNKNOWN"
colnames(test_matrix_aligned)[is.na(colnames(test_matrix_aligned))] <- "UNKNOWN"

all.equal(colnames(train_matrix), colnames(test_matrix_aligned))  # Should return TRUE


```

```{r}
# Apply PCA to aligned test_matrix
test_pca_scores <- predict(pca_result, newdata = test_matrix_aligned)

# Use the same principal components as in training
test_pca_reduced <- test_pca_scores[, 1:(ncol(binary_model$coefficients) - 1)]

# Predict binary labels
test_pca_df <- as.data.frame(test_pca_reduced)
binary_preds <- predict(binary_model, newdata = test_pca_df, type = "response")
binary_labels <- ifelse(binary_preds > 0.5, "1", "0")


```

#### 3.3 Multiclass prediction

### 4: Combine Predictions
```{r}
pred_df <- data.frame(
  .id = claims_test$.id,
  bclass.pred = binary_labels,
  mclass.pred = multiclass_preds
)


saveRDS(pred_df, "predictions.rds")

```

### 5.Export Deployable Model(maybe don't needed, done in previous steps)
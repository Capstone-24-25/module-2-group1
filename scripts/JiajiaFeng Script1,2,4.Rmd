
## Preparation
```{r}
load('data2/claims-raw.RData')
```

```{r}
ls()
```

```{r}
library(rvest)
library(tidytext)
library(dplyr)
library(tidyverse)
library(textstem)
library(rvest)
library(qdapRegex)
library(stopwords)
library(tokenizers)
```


## Preliminary Task1 (5 steps)

### 1.Scrape both header and paragraph content
```{r}

# Why use tryCatch: prevent the entire script from failing due to an issue with a single piece of HTML content
extract_content <- function(html_content) {
  tryCatch({
    # Read the HTML content
    page <- read_html(html_content)
    
    # Extract headers and paragraphs
    headers <- page %>% html_nodes("h1, h2, h3") %>% html_text()
    paragraphs <- page %>% html_nodes("p") %>% html_text()
    
    # Combine headers and paragraphs
    combined_content <- c(headers, paragraphs)
    return(paste(combined_content, collapse = " "))
  }, error = function(e) {
    # Return NA or an empty string if an error occurs
    return(NA)
  })
}

# Apply the function to the 'text_tmp' column
claims_raw$content_combined <- sapply(claims_raw$text_tmp, extract_content)

```

### 2.Tokenize the text
```{r}
# Tokenize the text data
data("stop_words")

tokenized_data <- claims_raw %>%
  unnest_tokens(word, content_combined) %>%
  anti_join(stop_words, by = "word")  # Remove stop words

# Create a document-term matrix (DTM)
dtm <- tokenized_data %>%
  count(.id, word) %>%
  cast_dtm(document = .id, term = word, value = n)

dtm_matrix <- as.matrix(dtm)

```

### 3.Principal Component Analysis (PCA)
```{r}
threshold <- 5 # reduce running time
dtm_filtered <- dtm_matrix[, colSums(dtm_matrix) > threshold]
pca_result <- prcomp(dtm_filtered, center = TRUE, scale. = TRUE)

```

### 4.Logistic Principal Component Regression
```{r}
# fix error: differing number of rows: pca_scores:2120, claims_raw$bclass:2165
rows_to_keep <- rownames(dtm_matrix)
claims_raw_filtered <- claims_raw %>% filter(.id %in% rows_to_keep)
```

```{r}
# Extract PCA scores and combine with the adjusted 'bclass', which is 'binary_class'
pca_scores <- pca_result$x

data_for_model <- data.frame(pca_scores, binary_class = claims_raw_filtered$bclass)
data_for_model$binary_class <- as.factor(data_for_model$binary_class)
```



```{r}
# Fix Warning: glm.fit: algorithm did not converge
binary_class_index <- which(names(data_for_model) == "binary_class")

# Choose the first 500 components (through Cumulative Variance Explained) and binary class column
data_for_model_reduced <- data_for_model[, c(1:500, binary_class_index)] 


names(data_for_model_reduced)
```


```{r}
# Fit logistic regression model using PCA components
logistic_model <- glm(binary_class ~ ., data = data_for_model_reduced, family = binomial)
```
### 5. Are binary class predictions improved using logistic principal component regression?
```{r}
library(pROC)

predicted_probs <- predict(logistic_model, type = "response")

# AUC after PCA
roc_curve <- roc(data_for_model_reduced$binary_class, predicted_probs)
auc(roc_curve)

# ROC Curve
plot(roc_curve)

```



## Preliminary Task 2 ()

### 1.Secondary Tokenization to obtain bigrams
```{r}
names(claims_raw) 
```
```{r}
# Tokenize the text to obtain bigrams
bigram_data <- claims_raw %>%
  unnest_tokens(bigram, content_combined, token = "ngrams", n = 2)


```

### 2.Fit Logistic Regression on word-tokenized data (unigrams) as baseline
```{r}
# What we do in task1  

# Fit logistic regression on PCA of word-tokenized data
pca_scores_words <- pca_result$x
word_model <- glm(binary_class ~ ., data = data_for_model_reduced, family = binomial)

# Predicted log-odds-ratios
word_predicted_log_odds <- predict(word_model, type = "link")


```
### 3.Input Predicted Log-Odds and PCA Scores of Bigrams
```{r}
# Fix error: memory limit 
# Count bigram frequencies across all documents
bigram_counts <- bigram_data %>%
  count(bigram) %>%
  filter(n > 5)  # Keep bigrams that occur more than 5 times

# Filter the bigram_data to include only frequent bigrams
bigram_data_filtered <- bigram_data %>%
  filter(bigram %in% bigram_counts$bigram)

# Create a smaller DTM
bigram_dtm <- bigram_data_filtered %>%
  count(.id, bigram) %>%
  cast_dtm(document = .id, term = bigram, value = n)

bigram_matrix <- as.matrix(bigram_dtm)

```

```{r}
bigram_pca_result <- prcomp(bigram_matrix, center = TRUE, scale. = TRUE)

```

```{r}
# Extract the top 10 principal components from bigram PCA
bigram_pca_scores <- bigram_pca_result$x
combined_data <- data.frame(
  log_odds = word_predicted_log_odds,
  bigram_pca_scores = bigram_pca_scores[, 1:10],  # Use top 10 bigram components
  binary_class = claims_raw_filtered$bclass
)
```


## Preliminary Task 2 Ver.2 ()
### 1.Bigram Tokenization
```{r}
# Bigram Tokenization
library(tidytext)

bigram_tokens <- claims_raw %>%
  unnest_tokens(output = bigram, input = content_combined, token = "ngrams", n = 2)

```
### 2.Filter Low-frequency Bigram
```{r}
# Filter frequent bigrams
bigram_counts <- bigram_tokens %>%
  count(bigram) %>%
  filter(n > 5)  # Only keep bigrams appearing more than 5 times

filtered_bigram_tokens <- bigram_tokens %>%
  filter(bigram %in% bigram_counts$bigram)
```

### 3.Construct the DTM of Bigram
```{r}
# Create a Document-Term Matrix for bigrams
bigram_dtm <- filtered_bigram_tokens %>%
  count(.id, bigram) %>%
  cast_dtm(document = .id, term = bigram, value = n)

```
### 4.PCA on Bigram's DTM
```{r}
# Convert to a dense matrix and perform PCA
bigram_matrix <- as.matrix(bigram_dtm)

# Perform PCA on the filtered bigram DTM
bigram_pca <- prcomp(bigram_matrix, center = TRUE, scale. = TRUE)

# Extract top N components (adjustable)
bigram_pca_scores <- bigram_pca$x[, 1:10]  # Use top 10 components

```

### 5. Combine Log-Odds of Word Prediction(unigram) and PCA Scores of Bigram

```{r}
# What we do in task1  

# Fit logistic regression on PCA of word-tokenized data
pca_scores_words <- pca_result$x
#word_model <- glm(binary_class ~ ., data = data_for_model_reduced, family = binomial)

# Predicted log-odds-ratios
predicted_log_odds <- predict(logistic_model, type = "link")

```

```{r}
# Step 1: Identify rows to keep
rows_to_keep <- intersect(
  names(predicted_log_odds),  # Use names() for vectors
  rownames(bigram_pca_scores)
)

# Step 2: Filter claims_raw_filtered to keep only matching rows
claims_raw_filtered <- claims_raw_filtered %>%
  filter(.id %in% rows_to_keep)

# Step 3: Subset predicted_log_odds and bigram_pca_scores to the same rows
predicted_log_odds <- predicted_log_odds[rows_to_keep]  # Simple indexing for vectors
bigram_pca_scores <- bigram_pca_scores[rows_to_keep, , drop = FALSE]  # Subset matrix

# Step 4: Combine aligned datasets
combined_features <- data.frame(
  log_odds_unigram = predicted_log_odds,
  bigram_pca_scores,
  binary_class = claims_raw_filtered$bclass  # Ensure alignment
)

```


```{r}
# Combine unigram log-odds and bigram PCA scores
combined_features <- data.frame(
  log_odds_unigram = predicted_log_odds,  # From your unigram model
  bigram_pca_scores,  # Top 10 bigram PCA scores
  binary_class = claims_raw_filtered$bclass  # Ensure consistent alignment
)

```



## Primary Task 1 ()

### 1. Load and Preprocess the Data
#### 1.1 Content Extraction
```{r}
load("data2/claims-raw.RData")
load("data2/claims-test.RData")

```

```{r}

nrow(claims_raw)
nrow(claims_test)

```
#### 1.2 Tokenization and Cleaning
```{r}

# Why use tryCatch: prevent the entire script from failing due to an issue with a single piece of HTML content
extract_content <- function(html_content) {
  tryCatch({
    # Read the HTML content
    page <- read_html(html_content)
    
    # Extract headers and paragraphs
    headers <- page %>% html_nodes("h1, h2, h3") %>% html_text()
    paragraphs <- page %>% html_nodes("p") %>% html_text()
    
    # Combine headers and paragraphs
    combined_content <- c(headers, paragraphs)
    return(paste(combined_content, collapse = " "))
  }, error = function(e) {
    # Return NA or an empty string if an error occurs
    return(NA)
  })
}

# Apply the function to the 'text_tmp' column
claims_raw$content_combined <- sapply(claims_raw$text_tmp, extract_content)
claims_test$content_combined <- sapply(claims_test$text_tmp, extract_content)

```

```{r}
library(tidytext)

# Tokenize and clean training data
train_tokens <- claims_raw %>%
  unnest_tokens(word, content_combined) %>%
  anti_join(stop_words, by = "word") %>%
  count(.id, word)

# Tokenize and clean test data
test_tokens <- claims_test %>%
  unnest_tokens(word, content_combined) %>%
  anti_join(stop_words, by = "word") %>%
  count(.id, word)
```


#### 1.3 Create Document-Term Matrices (DTMs)
```{r}
train_dtm <- train_tokens %>%
  cast_dtm(document = .id, term = word, value = n)

test_dtm <- test_tokens %>%
  cast_dtm(document = .id, term = word, value = n)

ncol(train_dtm)
ncol(test_dtm)

```

### 2.Train Models
#### 2.1 Binary Classification with Logistic Regression
```{r}
# Ensure Task 1 logistic model is available (don't forget to run it in the task1)
binary_model <- logistic_model  # Task 1 logistic regression model

saveRDS(binary_model, "binary_model.rds")

```

#### 2.2 Multiclass Classification with SVM

```{r}
library(e1071)

# Convert training DTM to matrix
train_matrix <- as.matrix(train_dtm)

# Multiclass labels
train_labels <- claims_raw$mclass  # Ensure this column exists in your data

```

```{r}
#Fix error train_matrix: 2120 and train_labels: 2165 
cat("Rows in train_matrix:", nrow(train_matrix), "\n")
cat("Rows in train_labels:", length(train_labels), "\n")

rows_to_keep <- rownames(train_matrix)

claims_raw_aligned <- claims_raw %>%
  filter(.id %in% rows_to_keep)

aligned_labels <- claims_raw_aligned$mclass

# Verify alignment
cat("Rows in aligned_labels:", length(aligned_labels), "\n")
cat("Rows in train_matrix (should match):", nrow(train_matrix), "\n")

```

```{r}

# Train SVM model
svm_multiclass_model <- svm(
  x = train_matrix,
  y = as.factor(aligned_labels),
  type = "C-classification", 
  kernel = "linear"           
)

# Save the SVM model
saveRDS(svm_multiclass_model, "svm_multiclass_model.rds")

```

### 3: Make Predictions
#### 3.0 Fix Errors before make Test Matrix

```{r}
#Fix error: train dtm and test dtm have different number of columns
anyNA(colnames(train_dtm))  # Check for NA column names
colnames(train_dtm)[is.na(colnames(train_dtm))] <- "UNKNOWN"
anyNA(colnames(test_dtm))  # Check for NA column names
colnames(test_dtm)[is.na(colnames(test_dtm))] <- "UNKNOWN"
# Check for missing columns in test_dtm
missing_cols <- setdiff(colnames(train_dtm), colnames(test_dtm))
print(missing_cols)  # Print missing column names

```

```{r}
# Add missing columns to test_dtm
missing_cols <- setdiff(colnames(train_dtm), colnames(test_dtm))
test_dtm_aligned <- cbind(test_dtm, matrix(0, nrow = nrow(test_dtm), ncol = length(missing_cols)))
colnames(test_dtm_aligned) <- c(colnames(test_dtm), missing_cols)

# Reorder columns to match train_dtm
test_dtm_aligned <- test_dtm_aligned[, colnames(train_dtm), drop = FALSE]

```
```{r}
# Verify dimensions match
cat("Columns in train_dtm:", ncol(train_dtm), "\n")
cat("Columns in test_dtm_aligned:", ncol(test_dtm_aligned), "\n")

# Check column name consistency
all.equal(colnames(train_dtm), colnames(test_dtm_aligned))

```

#### 3.1 Prepare Aligned Test Matrix

```{r}
test_matrix <- as.matrix(test_dtm_aligned)
head(test_dtm_aligned)
```

#### 3.2 Binary prediction
```{r}
# Align test DTM with train DTM
missing_cols <- setdiff(colnames(train_dtm), colnames(test_dtm))
test_dtm_aligned <- cbind(test_dtm, matrix(0, nrow = nrow(test_dtm), ncol = length(missing_cols)))
colnames(test_dtm_aligned) <- c(colnames(test_dtm), missing_cols)
test_dtm_aligned <- test_dtm_aligned[, colnames(train_dtm), drop = FALSE]

```

```{r}

# Convert aligned test DTM to matrix
test_matrix <- as.matrix(test_dtm_aligned)



# Predict binary labels
binary_preds <- predict(binary_model, type = "response")
binary_labels <- ifelse(binary_preds > 0.5, "1", "0")  # Convert probabilities to binary labels


```

#### 3.3 Multiclass prediction
```{r}
# Predict multiclass labels
multiclass_preds <- predict(svm_multiclass_model, test_matrix)

```


### 4: Combine Predictions
```{r}
# Ensure all predictions align with .id in claims_test
n_test <- nrow(claims_test)

# Fix binary_labels
if (length(binary_labels) > n_test) {
  binary_labels <- binary_labels[1:n_test]  # Trim excess rows
} else if (length(binary_labels) < n_test) {
  binary_labels <- c(binary_labels, rep(NA, n_test - length(binary_labels)))  # Fill missing with NA
}

# Fix multiclass_preds
if (length(multiclass_preds) > n_test) {
  multiclass_preds <- multiclass_preds[1:n_test]  # Trim excess rows
} else if (length(multiclass_preds) < n_test) {
  multiclass_preds <- c(multiclass_preds, rep(NA, n_test - length(multiclass_preds)))  # Fill missing with NA
}

# results/preds-group[N].RData
pred_df <- data.frame(
  .id_first = claims_test$.id,
  bclass.pred = binary_labels,
  mclass.pred = multiclass_preds
)


saveRDS(pred_df, "preds-group1.rds")

```

# Multiclass Test Accuracy
```{r}
multiclass_pred <- tibble(
  .id_first = names(multiclass_preds),
  pred_class = as.factor(multiclass_preds)
)

pred_df2 <- pred_df %>%
  rownames_to_column(var = ".id")

label_map <- c(
  "1" = "N/A: No relevant content.",
  "2" = "Physical Activity",
  "3" = "Possible Fatality",
  "4" = "Potentially unlawful activity",
  "5" = "Other claim content")

df_with_truth <- pred_df2 %>%
  inner_join(claims_raw, by = '.id') %>%
  mutate(mclass.pred = factor(mclass.pred, levels = 1:5, labels = label_map))



panel <- metric_set(sensitivity, 
                    specificity, 
                    accuracy)

mc_accuracy_panel <- df_with_truth %>% panel(truth = mclass, 
                  estimate = mclass.pred, 
                  event_level = 'second')

saveRDS(mc_accuracy_panel, "../writeups/mc_accuracy_panel.rds")
```

